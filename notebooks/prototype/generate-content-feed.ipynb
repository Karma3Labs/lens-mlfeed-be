{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179e333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "# $ cd /opt\n",
    "# /opt$ sudo ln -s ~/apps/spark-3.4.0-bin-hadoop3 spark\n",
    "findspark.init(\"/opt/spark\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ac33cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/24 23:00:01 WARN Utils: Your hostname, VIJAYs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.87.20 instead (on interface en0)\n",
      "23/05/24 23:00:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/05/24 23:00:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# import pyspark\n",
    "# sc = pyspark.SparkContext(appName=\"globalContent\")\n",
    "from pathlib import Path\n",
    "pg_jar = str(Path('~/apps/postgresql-42.5.4.jar').expanduser().resolve())\n",
    "gs_jar = str(Path('~/apps/gcs-connector-hadoop2-2.2.13-shaded.jar').expanduser().resolve())\n",
    "# bq_jar = str(Path('~/apps/spark-bigquery-with-dependencies_2.12-0.30.0.jar').expanduser().resolve())\n",
    "spark_jars = f\"{pg_jar},{gs_jar}\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"LensFeatures\") \\\n",
    "            .config(\"spark.jars\", spark_jars) \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa629d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sections is not required if you are running on Google Cloud Dataproc Serverless\n",
    "spark.conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "spark.conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "spark.conf.set(\"google.cloud.auth.service.account.enable\", \"true\")\n",
    "spark.conf.set(\"google.cloud.auth.service.account.json.keyfile\",\"../.eigen1-vijay-gcp.credentials.json\")\n",
    "spark.conf.set('fs.gs.auth.type','SERVICE_ACCOUNT_JSON_KEYFILE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65bff9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(f\"gs://vijay-lens-ml/predictions/20230522053757_xgbcl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7336c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where(f\"recommend != 'NO'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50a29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records $391650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"total number of records ${df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed95f71f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region: string (nullable = true)\n",
      " |-- collects: long (nullable = true)\n",
      " |-- followship_score: double (nullable = true)\n",
      " |-- custom_filters_gardener_flagged: string (nullable = true)\n",
      " |-- upvotes: long (nullable = true)\n",
      " |-- content_warning: string (nullable = true)\n",
      " |-- mirrors: long (nullable = true)\n",
      " |-- is_original: string (nullable = true)\n",
      " |-- is_content_warning: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- followship_rank: long (nullable = true)\n",
      " |-- downvotes: long (nullable = true)\n",
      " |-- main_content_focus: string (nullable = true)\n",
      " |-- comments: long (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- max_age: long (nullable = true)\n",
      " |-- max_mirrors: long (nullable = true)\n",
      " |-- max_collects: long (nullable = true)\n",
      " |-- max_comments: long (nullable = true)\n",
      " |-- post_score: double (nullable = true)\n",
      " |-- post_id: string (nullable = true)\n",
      " |-- dtime: long (nullable = true)\n",
      " |-- recommend: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b4334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"post_id\", \"recommend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5675c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total_yes = df.select('post_id').where(df.recommend == 'YES').count()\n",
    "total_maybe = df.select('post_id').where(df.recommend == 'YES').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d92951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_yes:193237 yes_fraction:0.0004967993\n",
      "total_maybe:193237 maybe_fraction:0.0001241998\n"
     ]
    }
   ],
   "source": [
    "# we need 100 rows but sampling sometimes returns less than 100; start with 120\n",
    "num_yes = 0.8*120\n",
    "num_maybe = 0.2*120\n",
    "\n",
    "yes_fraction = round(num_yes / total_yes, 10)\n",
    "print(f\"total_yes:{total_yes} yes_fraction:{yes_fraction}\")\n",
    "\n",
    "maybe_fraction = round(num_maybe / total_maybe, 10)\n",
    "print(f\"total_maybe:{total_maybe} maybe_fraction:{maybe_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9df0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sampleBy(\"recommend\", fractions={'YES': yes_fraction, 'MAYBE': maybe_fraction}, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed820e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of sampled records $119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:===========================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"total number of sampled records ${sample_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc2d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, monotonically_increasing_id\n",
    "sample_df = sample_df.select(\n",
    "                        lit(\"ml-xgb-followship\").alias(\"strategy_name\"), # \"EigenTrust + ML\"\n",
    "                        \"post_id\", \n",
    "                        monotonically_increasing_id().alias('v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f04927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- strategy_name: string (nullable = false)\n",
      " |-- post_id: string (nullable = true)\n",
      " |-- v: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5158bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(strategy_name='ml-xgb-followship', post_id='0x51fe-0x0599', v=0),\n",
       " Row(strategy_name='ml-xgb-followship', post_id='0xd523-0x0287', v=1),\n",
       " Row(strategy_name='ml-xgb-followship', post_id='0x0100c0-0x031c', v=2),\n",
       " Row(strategy_name='ml-xgb-followship', post_id='0x012751-0xbd', v=3),\n",
       " Row(strategy_name='ml-xgb-followship', post_id='0x01adad-0xfa', v=4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a6eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC URL: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "# 'jdbc:postgresql://dbhost:dbport/dbname?user=username&password=secret'\n",
    "jdbc_url = getpass.getpass(prompt='JDBC URL: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668ecd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample_df.limit(100).write.format(\"jdbc\")\\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"feed\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da134524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k3l-recommendation-env3",
   "language": "python",
   "name": "k3l-recommendation-env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
